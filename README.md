# üìö Sistema RAG com consultas Inteligentes

Aplica√ß√£o Streamlit que permite **carregar arquivos PDF ou EPUB** e fazer perguntas com base no conte√∫do utilizando **RAG (Retrieval-Augmented Generation)**, **FAISS** para busca sem√¢ntica e o modelo **Mistral-Saba-24B via API da Groq**.

## üìé Exemplo de uso

1. Envie um arquivo PDF ou EPUB (ex: livro, artigo, etc).
2. Ap√≥s o processamento, digite uma pergunta como:
   > "Qual √© o tema principal do cap√≠tulo 2?"
3. A resposta ser√° gerada com base no conte√∫do lido e indexado.

---
<div align="center">
<img src="https://github.com/user-attachments/assets/e1ca8ebc-bd55-4914-8a3d-47e3457a048d" width="1000px" />
<img src="https://github.com/user-attachments/assets/eb8365ef-5c47-435e-8140-a42f0c956426" width="1000px" />
</div>

## üîß Tecnologias utilizadas

- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [FAISS (Facebook AI Similarity Search)](https://github.com/facebookresearch/faiss)
- [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/) (para PDFs)
- [Unstructured](https://github.com/Unstructured-IO/unstructured) (para EPUBs)
- [Hugging Face Embeddings](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- [Groq API](https://console.groq.com/) com o modelo `mistral-saba-24b`

---

## üöÄ Como rodar o projeto

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/liedsoon/Consultor-de-livros-RAG.git
```

### 2. Crie um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate  # no Linux/Mac
venv\Scripts\activate     # no Windows
```

### 3. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configure a chave da API Groq

Crie um arquivo `.env` na raiz do projeto com o seguinte conte√∫do:

```env
GROQ_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

Voc√™ pode obter a chave em: https://console.groq.com/

---

## ‚ñ∂Ô∏è Executando a aplica√ß√£o

```bash
streamlit run app.py
```

---

## üß† Como funciona

1. O usu√°rio faz upload de um arquivo PDF ou EPUB.
2. O conte√∫do √© dividido em pequenos blocos de texto (chunks).
3. Os chunks s√£o vetorizados usando embeddings do HuggingFace.
4. Os vetores s√£o armazenados em um √≠ndice FAISS.
5. O usu√°rio envia uma pergunta, que √© respondida com base nos trechos mais relevantes do documento utilizando o modelo **Mistral-Saba-24B** da Groq.


